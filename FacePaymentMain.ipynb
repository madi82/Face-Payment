{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i1BRlFgv5hj2",
        "outputId": "f94f1290-1793-426d-cc49-b11fd03ca73b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Face-Payment'...\n",
            "remote: Enumerating objects: 89, done.\u001b[K\n",
            "remote: Counting objects: 100% (89/89), done.\u001b[K\n",
            "remote: Compressing objects: 100% (66/66), done.\u001b[K\n",
            "remote: Total 89 (delta 27), reused 68 (delta 16), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (89/89), 4.91 MiB | 4.00 MiB/s, done.\n",
            "/content/Face-Payment\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting retina-face\n",
            "  Downloading retina_face-0.0.13-py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: gdown>=3.10.1 in /usr/local/lib/python3.9/dist-packages (from retina-face) (4.6.6)\n",
            "Requirement already satisfied: tensorflow>=1.9.0 in /usr/local/lib/python3.9/dist-packages (from retina-face) (2.12.0)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.9/dist-packages (from retina-face) (1.22.4)\n",
            "Requirement already satisfied: opencv-python>=3.4.4 in /usr/local/lib/python3.9/dist-packages (from retina-face) (4.7.0.72)\n",
            "Requirement already satisfied: Pillow>=5.2.0 in /usr/local/lib/python3.9/dist-packages (from retina-face) (8.4.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.9/dist-packages (from gdown>=3.10.1->retina-face) (1.16.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from gdown>=3.10.1->retina-face) (4.65.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.9/dist-packages (from gdown>=3.10.1->retina-face) (2.27.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from gdown>=3.10.1->retina-face) (3.10.7)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.9/dist-packages (from gdown>=3.10.1->retina-face) (4.11.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow>=1.9.0->retina-face) (2.12.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.9/dist-packages (from tensorflow>=1.9.0->retina-face) (3.3.0)\n",
            "Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.9/dist-packages (from tensorflow>=1.9.0->retina-face) (2.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow>=1.9.0->retina-face) (2.2.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow>=1.9.0->retina-face) (1.14.1)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow>=1.9.0->retina-face) (3.8.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow>=1.9.0->retina-face) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.9/dist-packages (from tensorflow>=1.9.0->retina-face) (1.53.0)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.9/dist-packages (from tensorflow>=1.9.0->retina-face) (0.4.7)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow>=1.9.0->retina-face) (0.4.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow>=1.9.0->retina-face) (16.0.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from tensorflow>=1.9.0->retina-face) (23.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow>=1.9.0->retina-face) (0.32.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow>=1.9.0->retina-face) (23.3.3)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow>=1.9.0->retina-face) (1.6.3)\n",
            "Requirement already satisfied: keras<2.13,>=2.12.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow>=1.9.0->retina-face) (2.12.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.9/dist-packages (from tensorflow>=1.9.0->retina-face) (4.5.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.9/dist-packages (from tensorflow>=1.9.0->retina-face) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from tensorflow>=1.9.0->retina-face) (67.6.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow>=1.9.0->retina-face) (1.4.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.9/dist-packages (from astunparse>=1.6.0->tensorflow>=1.9.0->retina-face) (0.40.0)\n",
            "Requirement already satisfied: scipy>=1.7 in /usr/local/lib/python3.9/dist-packages (from jax>=0.3.15->tensorflow>=1.9.0->retina-face) (1.10.1)\n",
            "Requirement already satisfied: ml-dtypes>=0.0.3 in /usr/local/lib/python3.9/dist-packages (from jax>=0.3.15->tensorflow>=1.9.0->retina-face) (0.0.4)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow>=1.9.0->retina-face) (1.8.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow>=1.9.0->retina-face) (0.7.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow>=1.9.0->retina-face) (3.4.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow>=1.9.0->retina-face) (0.4.6)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow>=1.9.0->retina-face) (2.17.0)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow>=1.9.0->retina-face) (2.2.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.9/dist-packages (from beautifulsoup4->gdown>=3.10.1->retina-face) (2.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests[socks]->gdown>=3.10.1->retina-face) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests[socks]->gdown>=3.10.1->retina-face) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests[socks]->gdown>=3.10.1->retina-face) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests[socks]->gdown>=3.10.1->retina-face) (3.4)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.9/dist-packages (from requests[socks]->gdown>=3.10.1->retina-face) (1.7.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow>=1.9.0->retina-face) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow>=1.9.0->retina-face) (0.2.8)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow>=1.9.0->retina-face) (5.3.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.13,>=2.12->tensorflow>=1.9.0->retina-face) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.9/dist-packages (from markdown>=2.6.8->tensorboard<2.13,>=2.12->tensorflow>=1.9.0->retina-face) (6.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.9/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow>=1.9.0->retina-face) (2.1.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.13,>=2.12->tensorflow>=1.9.0->retina-face) (3.15.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.9/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow>=1.9.0->retina-face) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.9/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.13,>=2.12->tensorflow>=1.9.0->retina-face) (3.2.2)\n",
            "Installing collected packages: retina-face\n",
            "Successfully installed retina-face-0.0.13\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/madi82/Face-Payment.git\n",
        "%cd Face-Payment/\n",
        "!pip install retina-face"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oYBXZMn8Iiqg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "outputId": "e5239951-d567-4a14-f644-204c3877fc3d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "arcface_weights.h5  will be downloaded to  /root/.deepface/weights/arcface_weights.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://github.com/serengil/deepface_models/releases/download/v1.0/arcface_weights.h5\n",
            "To: /root/.deepface/weights/arcface_weights.h5\n",
            "100%|██████████| 137M/137M [00:01<00:00, 72.7MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "---------------------------------------\n",
            "\n",
            "\n",
            "Enter 1 for Payment by Face?\n",
            "Enter 2 for Create account?\n",
            "Enter 5 to exit : 2\n",
            "\n",
            "\n",
            "---------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    var video;\n",
              "    var div = null;\n",
              "    var stream;\n",
              "    var captureCanvas;\n",
              "    var imgElement;\n",
              "    var labelElement;\n",
              "    \n",
              "    var pendingResolve = null;\n",
              "    var shutdown = false;\n",
              "    \n",
              "    function removeDom() {\n",
              "       stream.getVideoTracks()[0].stop();\n",
              "       video.remove();\n",
              "       div.remove();\n",
              "       video = null;\n",
              "       div = null;\n",
              "       stream = null;\n",
              "       imgElement = null;\n",
              "       captureCanvas = null;\n",
              "       labelElement = null;\n",
              "    }\n",
              "    \n",
              "    function onAnimationFrame() {\n",
              "      if (!shutdown) {\n",
              "        window.requestAnimationFrame(onAnimationFrame);\n",
              "      }\n",
              "      if (pendingResolve) {\n",
              "        var result = \"\";\n",
              "        if (!shutdown) {\n",
              "          captureCanvas.getContext('2d').drawImage(video, 0, 0, 640, 480);\n",
              "          result = captureCanvas.toDataURL('image/jpeg', 0.8)\n",
              "        }\n",
              "        var lp = pendingResolve;\n",
              "        pendingResolve = null;\n",
              "        lp(result);\n",
              "      }\n",
              "    }\n",
              "    \n",
              "    async function createDom() {\n",
              "      if (div !== null) {\n",
              "        return stream;\n",
              "      }\n",
              "\n",
              "      div = document.createElement('div');\n",
              "      div.style.border = '2px solid black';\n",
              "      div.style.padding = '3px';\n",
              "      div.style.width = '100%';\n",
              "      div.style.maxWidth = '600px';\n",
              "      document.body.appendChild(div);\n",
              "      \n",
              "           \n",
              "      video = document.createElement('video');\n",
              "      video.style.display = 'block';\n",
              "      video.width = div.clientWidth - 6;\n",
              "      video.setAttribute('playsinline', '');\n",
              "      video.onclick = () => { shutdown = true; };\n",
              "      stream = await navigator.mediaDevices.getUserMedia(\n",
              "          {video: { facingMode: \"environment\"}});\n",
              "      div.appendChild(video);\n",
              "\n",
              "      imgElement = document.createElement('img');\n",
              "      imgElement.style.position = 'absolute';\n",
              "      imgElement.style.zIndex = 1;\n",
              "      imgElement.onclick = () => { shutdown = true; };\n",
              "      div.appendChild(imgElement);\n",
              "      \n",
              "      const instruction = document.createElement('div');\n",
              "      instruction.innerHTML = \n",
              "          '<span style=\"blue: red; font-weight: bold;\">' +\n",
              "          'click here to stop the video</span>';\n",
              "      div.appendChild(instruction);\n",
              "      instruction.onclick = () => { shutdown = true; };\n",
              "      \n",
              "      video.srcObject = stream;\n",
              "      await video.play();\n",
              "\n",
              "      captureCanvas = document.createElement('canvas');\n",
              "      captureCanvas.width = 640; \n",
              "      captureCanvas.height = 480; \n",
              "      window.requestAnimationFrame(onAnimationFrame);\n",
              "      \n",
              "      return stream;\n",
              "    }\n",
              "    async function stream_frame() {\n",
              "      if (shutdown) {\n",
              "        removeDom();\n",
              "        shutdown = false;\n",
              "        return '';\n",
              "      }\n",
              "\n",
              "      var preCreate = Date.now();\n",
              "      stream = await createDom();\n",
              "      \n",
              "      var preShow = Date.now();\n",
              "  \n",
              "            \n",
              "\n",
              "      \n",
              "      var preCapture = Date.now();\n",
              "      var result = await new Promise(function(resolve, reject) {\n",
              "        pendingResolve = resolve;\n",
              "      });\n",
              "      shutdown = false;\n",
              "      \n",
              "      return {'create': preShow - preCreate, \n",
              "              'show': preCapture - preShow, \n",
              "              'capture': Date.now() - preCapture,\n",
              "              'img': result};\n",
              "    }\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your name: Shantanu\n",
            "Enter your balance: 890\n",
            "retinaface.h5 will be downloaded from the url https://github.com/serengil/deepface_models/releases/download/v1.0/retinaface.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://github.com/serengil/deepface_models/releases/download/v1.0/retinaface.h5\n",
            "To: /root/.deepface/weights/retinaface.h5\n",
            "100%|██████████| 119M/119M [00:01<00:00, 95.1MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "User enrolled!!!\n",
            "\n",
            "---------------------------------------\n",
            "\n",
            "\n",
            "Enter 1 for Payment by Face?\n",
            "Enter 2 for Create account?\n",
            "Enter 5 to exit : 5\n"
          ]
        }
      ],
      "source": [
        "from liveliness import test\n",
        "import ArcFace\n",
        "from retinaface import RetinaFace\n",
        "from retinaface.commons import postprocess\n",
        "from PIL import Image as Img\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import json\n",
        "from os import path\n",
        "import logging\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import time\n",
        "import random\n",
        "\n",
        "\n",
        "# Global variable\n",
        "#---------------------------------------\n",
        "# Main path to store all photos of user\n",
        "path_database = \"/content/Face-Payment/database/\"\n",
        "path_logs = \"/content/Face-Payment/logs/\"\n",
        "cosine_threshold = 0.68\n",
        "trans_key = 0\n",
        "loaded_db = []\n",
        "logging.basicConfig(filename=path_logs+'app.log',\n",
        "                    filemode='a',\n",
        "                    format='%(asctime)s, %(levelname)s, %(message)s',\n",
        "                    level=logging.DEBUG,\n",
        "                    force=True)\n",
        "model = ArcFace.loadModel()\n",
        "\n",
        "# For Video stream\n",
        "from IPython.display import display, Javascript, Image\n",
        "from google.colab.output import eval_js\n",
        "import html\n",
        "from base64 import b64decode, b64encode\n",
        "import cv2\n",
        "import PIL\n",
        "import io\n",
        "\n",
        "def jsob_to_image(js_object):\n",
        "  # decode base64 image\n",
        "  image_bytes = b64decode(js_object.split(',')[1])\n",
        "  # convert bytes to numpy array\n",
        "  img_array = np.frombuffer(image_bytes, dtype=np.uint8)\n",
        "  # convert numpy array into OpenCV BGR \n",
        "  frame = cv2.imdecode(img_array, flags=1)\n",
        "\n",
        "  return frame\n",
        "\n",
        "\n",
        "def video_stream():\n",
        "  js = Javascript('''\n",
        "    var video;\n",
        "    var div = null;\n",
        "    var stream;\n",
        "    var captureCanvas;\n",
        "    var imgElement;\n",
        "    var labelElement;\n",
        "    \n",
        "    var pendingResolve = null;\n",
        "    var shutdown = false;\n",
        "    \n",
        "    function removeDom() {\n",
        "       stream.getVideoTracks()[0].stop();\n",
        "       video.remove();\n",
        "       div.remove();\n",
        "       video = null;\n",
        "       div = null;\n",
        "       stream = null;\n",
        "       imgElement = null;\n",
        "       captureCanvas = null;\n",
        "       labelElement = null;\n",
        "    }\n",
        "    \n",
        "    function onAnimationFrame() {\n",
        "      if (!shutdown) {\n",
        "        window.requestAnimationFrame(onAnimationFrame);\n",
        "      }\n",
        "      if (pendingResolve) {\n",
        "        var result = \"\";\n",
        "        if (!shutdown) {\n",
        "          captureCanvas.getContext('2d').drawImage(video, 0, 0, 640, 480);\n",
        "          result = captureCanvas.toDataURL('image/jpeg', 0.8)\n",
        "        }\n",
        "        var lp = pendingResolve;\n",
        "        pendingResolve = null;\n",
        "        lp(result);\n",
        "      }\n",
        "    }\n",
        "    \n",
        "    async function createDom() {\n",
        "      if (div !== null) {\n",
        "        return stream;\n",
        "      }\n",
        "\n",
        "      div = document.createElement('div');\n",
        "      div.style.border = '2px solid black';\n",
        "      div.style.padding = '3px';\n",
        "      div.style.width = '100%';\n",
        "      div.style.maxWidth = '600px';\n",
        "      document.body.appendChild(div);\n",
        "      \n",
        "           \n",
        "      video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      video.width = div.clientWidth - 6;\n",
        "      video.setAttribute('playsinline', '');\n",
        "      video.onclick = () => { shutdown = true; };\n",
        "      stream = await navigator.mediaDevices.getUserMedia(\n",
        "          {video: { facingMode: \"environment\"}});\n",
        "      div.appendChild(video);\n",
        "\n",
        "      imgElement = document.createElement('img');\n",
        "      imgElement.style.position = 'absolute';\n",
        "      imgElement.style.zIndex = 1;\n",
        "      imgElement.onclick = () => { shutdown = true; };\n",
        "      div.appendChild(imgElement);\n",
        "      \n",
        "      const instruction = document.createElement('div');\n",
        "      instruction.innerHTML = \n",
        "          '<span style=\"blue: red; font-weight: bold;\">' +\n",
        "          'click here to stop the video</span>';\n",
        "      div.appendChild(instruction);\n",
        "      instruction.onclick = () => { shutdown = true; };\n",
        "      \n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      captureCanvas = document.createElement('canvas');\n",
        "      captureCanvas.width = 640; \n",
        "      captureCanvas.height = 480; \n",
        "      window.requestAnimationFrame(onAnimationFrame);\n",
        "      \n",
        "      return stream;\n",
        "    }\n",
        "    async function stream_frame() {\n",
        "      if (shutdown) {\n",
        "        removeDom();\n",
        "        shutdown = false;\n",
        "        return '';\n",
        "      }\n",
        "\n",
        "      var preCreate = Date.now();\n",
        "      stream = await createDom();\n",
        "      \n",
        "      var preShow = Date.now();\n",
        "  \n",
        "            \n",
        "\n",
        "      \n",
        "      var preCapture = Date.now();\n",
        "      var result = await new Promise(function(resolve, reject) {\n",
        "        pendingResolve = resolve;\n",
        "      });\n",
        "      shutdown = false;\n",
        "      \n",
        "      return {'create': preShow - preCreate, \n",
        "              'show': preCapture - preShow, \n",
        "              'capture': Date.now() - preCapture,\n",
        "              'img': result};\n",
        "    }\n",
        "    ''')\n",
        "\n",
        "  display(js)\n",
        "  \n",
        "def video_frame():\n",
        "  data = eval_js('stream_frame()')\n",
        "  return data\n",
        "\n",
        "\n",
        "#-------------------------------------------------------------------\n",
        "def detect_face(path_specific_image: np.ndarray):\n",
        "\n",
        "  detected_face = []\n",
        "  align_det_face = [] \n",
        "  facial_information = []\n",
        "\n",
        "  facial_information = RetinaFace.detect_faces(path_specific_image)\n",
        "  logging.info(\"Facial information: %s\",facial_information)\n",
        "\n",
        "  for k, v in facial_information.items():\n",
        "    facial_area = v['facial_area']\n",
        "    landmarks = v['landmarks']\n",
        "    detected_face = path_specific_image[facial_area[1]: facial_area[3], facial_area[0]: facial_area[2]]\n",
        "    logging.info(\"Check detected image of Transaction ID : %s\",trans_key)\n",
        "    cv2.imwrite(path_logs+\"DetectedImage_\"+str(trans_key)+\".jpg\", detected_face)\n",
        "    \n",
        "    # Below code is to represent square on face and landmarks\n",
        "    # highlight_image = path_specific_image\n",
        "    # cv2.rectangle(highlight_image, (facial_area[2], facial_area[3]), (facial_area[0], facial_area[1]), (255, 255, 255), 1)\n",
        "    # cv2.imwrite(path_logs+\"HighlightImage_\"+str(trans_key)+\".jpg\", highlight_image)\n",
        "\n",
        "    # landmark_image = path_specific_image\n",
        "    # cv2.circle(landmark_image, (round(landmarks[\"left_eye\"][0]),round(landmarks[\"left_eye\"][1])), 5, (0, 0, 255), -1)\n",
        "    # cv2.circle(landmark_image, (round(landmarks[\"right_eye\"][0]),round(landmarks[\"right_eye\"][1])), 5, (0, 0, 255), -1)\n",
        "    # cv2.circle(landmark_image, (round(landmarks[\"nose\"][0]),round(landmarks[\"nose\"][1])), 5, (0, 0, 255), -1)\n",
        "    # cv2.circle(landmark_image, (round(landmarks[\"mouth_left\"][0]),round(landmarks[\"mouth_left\"][1])), 5, (0, 0, 255), -1)\n",
        "    # cv2.circle(landmark_image, (round(landmarks[\"mouth_right\"][0]),round(landmarks[\"mouth_right\"][1])), 5, (0, 0, 255), -1)\n",
        "    # cv2.imwrite(path_logs+\"LandmarkImage_\"+str(trans_key)+\".jpg\", landmark_image)\n",
        "\n",
        "  # Alignment of image\n",
        "  left_eye = landmarks[\"left_eye\"]\n",
        "  right_eye = landmarks[\"right_eye\"]\n",
        "  nose = landmarks[\"nose\"]\n",
        "  align_det_face = postprocess.alignment_procedure(detected_face, right_eye, left_eye, nose)\n",
        "  cv2.imwrite(path_logs+\"AlingedImage_\"+str(trans_key)+\".jpg\", align_det_face)\n",
        "  \n",
        "  return detected_face, align_det_face, facial_information\n",
        "\n",
        "#-------------------------------------------------------------------\n",
        "def preprocess_face(img, target_size=(112,112)):\n",
        "\n",
        "    #resize image to expected shape\n",
        "    if img.shape[0] > 0 and img.shape[1] > 0:\n",
        "      factor_0 = target_size[0] / img.shape[0]\n",
        "      factor_1 = target_size[1] / img.shape[1]\n",
        "      factor = min(factor_0, factor_1)\n",
        "\n",
        "      dsize = (int(img.shape[1] * factor), int(img.shape[0] * factor))\n",
        "      img = cv2.resize(img, dsize)\n",
        "\n",
        "      # Then pad the other side to the target size by adding black pixels\n",
        "      diff_0 = target_size[0] - img.shape[0]\n",
        "      diff_1 = target_size[1] - img.shape[1]\n",
        "      img = np.pad(img, ((diff_0 // 2, diff_0 - diff_0 // 2), (diff_1 // 2, diff_1 - diff_1 // 2), (0, 0)), 'constant')\n",
        "\n",
        "    logging.info(\"Check pre-processed image of Transaction ID : %s\",trans_key)\n",
        "    cv2.imwrite(path_logs+\"PreprocessedImage_\"+str(trans_key)+\".jpg\", img)\n",
        "\n",
        "    #normalizing the image pixels\n",
        "    img_pixels = image.img_to_array(img)\n",
        "    img_pixels = np.expand_dims(img_pixels, axis = 0)\n",
        "    img_pixels /= 255 #normalize input in [0, 1]\n",
        "\n",
        "\n",
        "    # Reference study: The faces are cropped and resized to 112×112,\n",
        "    # and each pixel (ranged between [0, 255]) in RGB images is normalised\n",
        "    # by subtracting 127.5 then divided by 128.\n",
        "    #img_pixels -= 127.5\n",
        "    #img_pixels /= 128\n",
        "    return img_pixels\n",
        "\n",
        "#-------------------------------------------------------------------\n",
        "def representation(img):\n",
        "  return model.predict(img, verbose=0)[0].tolist()\n",
        "\n",
        "#-------------------------------------------------------------------\n",
        "def findCosineDistance(source_representation, test_representation):\n",
        "    a = np.matmul(np.transpose(source_representation), test_representation)\n",
        "    b = np.sum(np.multiply(source_representation, source_representation))\n",
        "    c = np.sum(np.multiply(test_representation, test_representation))\n",
        "    return 1 - (a / (np.sqrt(b) * np.sqrt(c)))\n",
        "\n",
        "#-------------------------------------------------------------------\n",
        "# This function used for Face recognition\n",
        "def get_all_distance(target_embedding):\n",
        "  distances = dict()\n",
        "  for key in loaded_db:\n",
        "    source_embedding = loaded_db[key][\"embedding\"]\n",
        "    distance = findCosineDistance(source_embedding, target_embedding)\n",
        "    distances[key] = distance\n",
        "\n",
        "  minimum_keys = [key for key in distances if distances[key]==min(distances.values())]\n",
        "  under_threshold_distance = dict()\n",
        "  for key in distances:\n",
        "    if distances[key] <= cosine_threshold:\n",
        "      under_threshold_distance[key] = distances[key]\n",
        "\n",
        "  predicted_person = [k for k, v in under_threshold_distance.items() if v == min(under_threshold_distance.values())]\n",
        "  predicted_person = predicted_person[0]\n",
        "\n",
        "  return predicted_person, distances\n",
        "\n",
        "#-------------------------------------------------------------------\n",
        "def load_database():\n",
        "  # Read JSON file\n",
        "  with open(path_database+\"database.json\") as fp:\n",
        "    jsonload = json.load(fp)\n",
        "  logging.info(\"Database loaded\")\n",
        "  return jsonload\n",
        "\n",
        "loaded_db = load_database()\n",
        "logging.info(\"Loaded DB : %s \", loaded_db)\n",
        "\n",
        "\n",
        "def menu():\n",
        "  print(\"\\n---------------------------------------\")\n",
        "  logging.info(\"\\n---------------------------------------\")\n",
        "  strs = ('\\n\\n'\n",
        "          'Enter 1 for Payment by Face?\\n'\n",
        "          'Enter 2 for Create account?\\n'\n",
        "          'Enter 5 to exit : ')\n",
        "  choice = input(strs)\n",
        "  return int(choice) \n",
        "\n",
        "while True:          \n",
        "  choice = menu()\n",
        "  if choice == 1:\n",
        "    print(\"\\n\\n---------------------------------------\")\n",
        "    trans_key = random.randint(1000, 9999)\n",
        "    logging.info(\"Transaction ID : %s\", trans_key)\n",
        "    # Get the webcam stream and forward it to python \n",
        "    video_stream()\n",
        "    validation = 1\n",
        "    while True:\n",
        "      frame_js = video_frame()\n",
        "      if not frame_js:\n",
        "        break\n",
        "      img = jsob_to_image(frame_js[\"img\"])\n",
        "      if validation == 1:\n",
        "        validation = validation - 1\n",
        "        logging.info(\"Check raw image of Transaction ID : %s\",trans_key)\n",
        "        cv2.imwrite(path_logs+\"RawImage_\"+str(trans_key)+\".jpg\", img)\n",
        "        logging.info(\"Checking for Anti-Spoofing\")\n",
        "        anti_spoof_res = test(img,'/content/Face-Payment/resources/anti_spoof_models', 0)\n",
        "        logging.info(\"Real/Fake face label: %s and Pred acc: %s and Pred time: %s\",anti_spoof_res[0],anti_spoof_res[1],anti_spoof_res[2])\n",
        "        if anti_spoof_res[0] == 1:\n",
        "          starttime = time.time()\n",
        "          print(f\"Transaction in progress...\")\n",
        "          predname = get_all_distance(representation(preprocess_face(detect_face(img)[1])))\n",
        "          logging.info(\"Predicted name: %s and All Distances: %s\",predname[0],predname[1])\n",
        "          cust_name = predname[0]                \n",
        "          cust_bal = loaded_db[cust_name][\"balance\"]\n",
        "          print(f\"Welcome {cust_name}\")\n",
        "          print(f\"Account balance : {cust_bal} CAD\")\n",
        "          updated_cust_bal = int(cust_bal)-20\n",
        "          print(f\"Remaining account balance : {updated_cust_bal} CAD\")\n",
        "          loaded_db[cust_name][\"balance\"] = updated_cust_bal\n",
        "          logging.info(\"Prediction cost: %s\",round((time.time() - starttime), 2))\n",
        "        else:\n",
        "          print(f\"Access denied!!!\")\n",
        "  elif choice == 2:\n",
        "    print(\"\\n\\n---------------------------------------\")\n",
        "    trans_key = random.randint(1000, 9999)\n",
        "    logging.info(\"Transaction ID : %s\", trans_key)\n",
        "    # Get the webcam stream and forward it to python \n",
        "    video_stream()\n",
        "    validation = 1\n",
        "    while True:\n",
        "      frame_js = video_frame()\n",
        "      if not frame_js:\n",
        "        break\n",
        "      img = jsob_to_image(frame_js[\"img\"])\n",
        "      if validation == 1:\n",
        "        validation = validation - 1\n",
        "        logging.info(\"Check raw image of Transaction ID : %s\",trans_key)\n",
        "        label = input(\"Enter your name: \")\n",
        "        balance = input(\"Enter your balance: \")\n",
        "        cv2.imwrite(path_database+\"\"+label+\".jpg\", img)\n",
        "        embedding = representation(preprocess_face(detect_face(img)[1]))\n",
        "        loaded_db[label] = {\"embedding\": embedding,\"balance\": balance}\n",
        "        print(f\"User enrolled!!!\")\n",
        "  elif choice == 5:\n",
        "    break"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}